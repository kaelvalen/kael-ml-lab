{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec9c3da",
   "metadata": {},
   "source": [
    "# üöÄ D2L Proje Yapƒ±sƒ± - Demo\n",
    "\n",
    "Bu notebook, projenin nasƒ±l kullanƒ±lacaƒüƒ±nƒ± g√∂sterir:\n",
    "- ‚úÖ Python mod√ºllerini kullanma\n",
    "- ‚úÖ CUDA kernellerini test etme\n",
    "- ‚úÖ G√∂rselle≈ütirme ara√ßlarƒ±\n",
    "- ‚úÖ Eƒüitim d√∂ng√ºs√º √∂rneƒüi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a926b87",
   "metadata": {},
   "source": [
    "## 1. Import'lar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca0cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# D2L √∂zel mod√ºller\n",
    "from d2l_custom.utils import Timer, try_gpu, gpu_info\n",
    "from d2l_custom.models import LinearRegression\n",
    "from d2l_custom.data import synthetic_data, load_data\n",
    "from d2l_custom.visualization import plot, plot_training_curve\n",
    "from d2l_custom.training import train\n",
    "\n",
    "# CUDA operasyonlarƒ± (derlenmi≈üse)\n",
    "try:\n",
    "    from d2l_custom.cuda_ops import custom_matmul, custom_relu\n",
    "    CUDA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  CUDA mod√ºlleri derli deƒüil. PyTorch fallback kullanƒ±lacak.\")\n",
    "    CUDA_AVAILABLE = False\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a01197a",
   "metadata": {},
   "source": [
    "## 2. Sentetik Veri √úretimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doƒürusal regresyon i√ßin sentetik veri\n",
    "true_w = torch.tensor([2.0, -3.4, 5.1])\n",
    "true_b = 4.2\n",
    "X, y = synthetic_data(true_w, true_b, num_examples=1000)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"True weights: {true_w.tolist()}\")\n",
    "print(f\"True bias: {true_b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d21f019",
   "metadata": {},
   "source": [
    "## 3. DataLoader Olu≈üturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_data(X, y, batch_size=32, train_ratio=0.8)\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa843a65",
   "metadata": {},
   "source": [
    "## 4. Model Olu≈üturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1735eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(in_features=3)\n",
    "device = try_gpu()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03)\n",
    "\n",
    "print(f\"Model: {model}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81aec64",
   "metadata": {},
   "source": [
    "## 5. Eƒüitim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e1f5d",
   "metadata": {},
   "source": [
    "## 6. G√∂rselle≈ütirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f5cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curve(\n",
    "    train_losses=history['train_loss'],\n",
    "    val_losses=history['test_loss']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08684d99",
   "metadata": {},
   "source": [
    "## 7. Sonu√ßlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √ñƒürenilen parametreleri g√∂ster\n",
    "learned_w = model.net.weight.data.squeeze()\n",
    "learned_b = model.net.bias.data.item()\n",
    "\n",
    "print(\"‚ïê\" * 50)\n",
    "print(\"Ger√ßek vs √ñƒürenilen Parametreler\")\n",
    "print(\"‚ïê\" * 50)\n",
    "print(f\"True w:    {true_w.tolist()}\")\n",
    "print(f\"Learned w: {learned_w.tolist()}\")\n",
    "print(f\"\")\n",
    "print(f\"True b:    {true_b:.3f}\")\n",
    "print(f\"Learned b: {learned_b:.3f}\")\n",
    "print(\"‚ïê\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38033dd",
   "metadata": {},
   "source": [
    "## 8. CUDA Kernelleri (Opsiyonel)\n",
    "\n",
    "Eƒüer CUDA mod√ºlleri derlenmi≈üse, performans kar≈üƒ±la≈ütƒ±rmasƒ± yapabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c14664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CUDA_AVAILABLE and torch.cuda.is_available():\n",
    "    N = 1024\n",
    "    A = torch.randn(N, N, device='cuda')\n",
    "    B = torch.randn(N, N, device='cuda')\n",
    "    \n",
    "    # PyTorch matmul\n",
    "    timer = Timer()\n",
    "    timer.start()\n",
    "    for _ in range(100):\n",
    "        C_torch = torch.mm(A, B)\n",
    "    torch.cuda.synchronize()\n",
    "    time_torch = timer.stop()\n",
    "    \n",
    "    # Custom CUDA matmul\n",
    "    timer.start()\n",
    "    for _ in range(100):\n",
    "        C_cuda = custom_matmul(A, B)\n",
    "    torch.cuda.synchronize()\n",
    "    time_cuda = timer.stop()\n",
    "    \n",
    "    print(f\"PyTorch matmul: {time_torch:.3f}s\")\n",
    "    print(f\"Custom CUDA matmul: {time_cuda:.3f}s\")\n",
    "    print(f\"Speedup: {time_torch/time_cuda:.2f}x\")\n",
    "    \n",
    "    # Doƒüruluk kontrol√º\n",
    "    error = (C_torch - C_cuda).abs().max().item()\n",
    "    print(f\"Max error: {error:.2e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  CUDA mevcut deƒüil veya mod√ºller derlenmemi≈ü.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2344bf6",
   "metadata": {},
   "source": [
    "## üéâ Tebrikler!\n",
    "\n",
    "D2L proje yapƒ±sƒ±nƒ± ba≈üarƒ±yla kullandƒ±nƒ±z. ≈ûimdi:\n",
    "\n",
    "1. **Roadmap'e** g√∂z atƒ±n: `notebooks/0_roadmap/roadmap.md`\n",
    "2. **B√∂l√ºmleri** inceleyin: `notebooks/01_introduction/`, `02_preliminaries/`, vs.\n",
    "3. **CUDA kernellerini** derleyin: `make cuda-build`\n",
    "4. **Testleri** √ßalƒ±≈ütƒ±rƒ±n: `make test`\n",
    "\n",
    "ƒ∞yi √ßalƒ±≈ümalar! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
