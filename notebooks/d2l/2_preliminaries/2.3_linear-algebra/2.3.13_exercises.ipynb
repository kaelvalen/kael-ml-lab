{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Prove that the transpose of the transpose of a matrix is the matrix itself: $(A^T)^T = A$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 4.],\n",
            "        [3., 4., 5.],\n",
            "        [5., 6., 7.]])\n"
          ]
        }
      ],
      "source": [
        "A = torch.tensor([[1.0, 2.0, 4.0], [3.0, 4.0, 5.0], [5.0, 6.0, 7.0]])\n",
        "print(A)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 3., 5.],\n",
            "        [2., 4., 6.],\n",
            "        [4., 5., 7.]])\n"
          ]
        }
      ],
      "source": [
        "B = A.T\n",
        "print(B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "B.T == A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Given two matrices A and B, show that sum and transposition commute: $(A + B)^T = A^T + B^T$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "C = A + B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C.T == A.T + B.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Given any square matrix A, is $A + A^T$ always symmetric? Can you prove the result by using only the results of the previous two exercises?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 2.,  5.,  9.],\n",
              "        [ 5.,  8., 11.],\n",
              "        [ 9., 11., 14.]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A + A.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. We defined the tensor X of shape (2, 3, 4) in this section. What is the output of len(X)? Write your answer without implementing any code, then check your answer using code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7],\n",
            "         [ 8,  9, 10, 11]],\n",
            "\n",
            "        [[12, 13, 14, 15],\n",
            "         [16, 17, 18, 19],\n",
            "         [20, 21, 22, 23]]])\n"
          ]
        }
      ],
      "source": [
        "X = torch.arange(24).reshape(2, 3, 4)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. For a tensor X of arbitrary shape, does len(X) always correspond to the length of a certain axis of X? What is that axis?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "axis 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " * If X has shape (3, 4), len(X) is 3.\n",
        "* If X has shape (2, 5, 6), len(X) is 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Run A / A.sum(axis=1) and see what happens. Can you analyze the results?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.1429, 0.1667, 0.2222],\n",
              "        [0.4286, 0.3333, 0.2778],\n",
              "        [0.7143, 0.5000, 0.3889]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A/A.sum(axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.1429, 0.2857, 0.5714],\n",
              "        [0.2500, 0.3333, 0.4167],\n",
              "        [0.2778, 0.3333, 0.3889]])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A / A.sum(axis=1, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(4.1111), tensor(4.1111))"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.mean(), A.sum()/A.numel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. When traveling between two points in downtown Manhattan, what is the distance that you need to cover in terms of the coordinates, i.e., in terms of avenues and streets? Can you travel diagonally?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Manhattan Distance = |x₂ - x₁| + |y₂ - y₁|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8. Consider a tensor of shape (2, 3, 4). What are the shapes of the summation outputs along axes 0, 1, and 2?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11]],\n",
              "\n",
              "        [[12, 13, 14, 15],\n",
              "         [16, 17, 18, 19],\n",
              "         [20, 21, 22, 23]]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[12, 14, 16, 18],\n",
              "        [20, 22, 24, 26],\n",
              "        [28, 30, 32, 34]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.sum(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[12, 15, 18, 21],\n",
              "        [48, 51, 54, 57]])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 6, 22, 38],\n",
              "        [54, 70, 86]])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.sum(axis=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9. Feed a tensor with three or more axes to the linalg.norm function and observe its output. What does this function compute for tensors of arbitrary shape?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(14.2829)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Shape: (2, 2, 2) - 3 boyutlu tensor\n",
        "tensor = torch.tensor([[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0, 8.0]]])\n",
        "\n",
        "result = torch.linalg.norm(tensor)\n",
        "print(result)  # tensor(14.2829)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 10. Consider three large matrices, say A ∈ R^(210×216), B ∈ R^(216×25) and C ∈ R^(25×214), initialized with Gaussian random variables. You want to compute the product ABC. Is there any difference in memory footprint and speed, depending on whether you compute (AB)C or A(BC)? Why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "A = torch.randn(210, 216)\n",
        "B = torch.randn(216, 25)\n",
        "C = torch.randn(25, 214)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "D = torch.mm(A, B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  56.6528,   26.2997,   40.8603,  ...,   21.3501, -100.0776,\n",
              "          -71.0474],\n",
              "        [ -15.0712,  223.0193,    9.4851,  ...,  -88.7356,  -87.2293,\n",
              "          -32.0949],\n",
              "        [ -58.4807,   54.9840, -132.1190,  ...,  107.7717,   78.8377,\n",
              "           61.3944],\n",
              "        ...,\n",
              "        [ -94.5637,  -88.8546,  -52.8458,  ...,   39.6504,   88.7390,\n",
              "          -93.2231],\n",
              "        [  68.4794,  143.8714,   58.9820,  ...,  -32.5493,   17.5290,\n",
              "          -46.4282],\n",
              "        [  57.9212,   40.8753,  -44.9338,  ...,    5.5768,   46.6423,\n",
              "          -51.4375]])"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mm(D, C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "E = torch.mm(B, C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  56.6528,   26.2997,   40.8603,  ...,   21.3501, -100.0776,\n",
              "          -71.0474],\n",
              "        [ -15.0712,  223.0194,    9.4851,  ...,  -88.7356,  -87.2294,\n",
              "          -32.0949],\n",
              "        [ -58.4808,   54.9840, -132.1190,  ...,  107.7717,   78.8377,\n",
              "           61.3944],\n",
              "        ...,\n",
              "        [ -94.5637,  -88.8546,  -52.8458,  ...,   39.6504,   88.7390,\n",
              "          -93.2231],\n",
              "        [  68.4794,  143.8714,   58.9820,  ...,  -32.5493,   17.5290,\n",
              "          -46.4282],\n",
              "        [  57.9212,   40.8753,  -44.9339,  ...,    5.5768,   46.6424,\n",
              "          -51.4374]])"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mm(A,E)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 11. Consider three large matrices, say A ∈ R^(210×216), B ∈ R^(216×25) and C ∈ R^(25×216). Is there any difference in speed depending on whether you compute AB or AC^T? Why? What changes if you initialize C = B^T without cloning memory? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12. Consider three matrices, say A, B, C ∈ R^(100×200). Construct a tensor with three axes by stacking [A, B, C]. What is the dimensionality? Slice out the second coordinate of the third axis to recover B. Check that your answer is correct."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "d2l",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
