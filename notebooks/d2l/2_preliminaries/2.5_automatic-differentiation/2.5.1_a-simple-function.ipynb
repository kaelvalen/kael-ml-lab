{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.5.1 A Simple Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A Simple Function Example\n",
        "\n",
        "## Function Definition\n",
        "Let's assume that we are interested in differentiating the function y = 2x·µÄx with respect to the column vector x. To start, we assign x an initial value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(4.0)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Before we calculate the gradient of ùë¶ with respect to ùë•, we need a place to store it. Ingeneral, we avoid allocating new memory every time we take a derivative because deeplearning requires successively computing derivatives with respect to the same parametersa great many times, and we might risk running out of memory. Note that the gradient of a scalar-valued function with respect to a vector x is vector-valued with the same shape asx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "x.requires_grad_(True)\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now calculate our func of x and assign the result on y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(28., grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = 2 * torch.dot(x, x)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we can now take the gradient of y with resp to x by calling its backward method. we can access the gradient via x's grad attr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.,  4.,  8., 12.])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We already know that the gradient of the function $y = 2x^\\top x$ with respect to $x$ should be $4x$. We can now verify that the automatic gradient computation and the expected result are identical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([True, True, True, True])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad == 4 * x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's calculate another function of $x$ and take its gradient. Note that PyTorch does not automatically reset the gradient buffer when we record a new gradient. Instead, the new gradient is added to the already-stored gradient. This behavior comes in handy when we want to optimize the sum of multiple objective functions. To reset the gradient buffer, we can call `x.grad.zero_()` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "x.grad.zero_()  # reset the gradient to zero\n",
        "y = x.sum()\n",
        "y.backward() # compute the gradient of y with respect to x\n",
        "print(x.grad)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "d2l",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
